# 向量数据的存储优化与GPU加速检索

近似最近邻搜索（ANNS）已成为数据库和人工智能基础设施的关键组成部分。不断增长的向量数据集给 ANNS 服务在性能、成本和准确性方面带来了重大挑战。现有 ANNS 系统均无法同时解决这些问题。

高维空间中的近似最近邻搜索(ANNS)旨在找出与给定查询向量最相似的前 k 个向量。该技术在数据挖掘、搜索引擎以及 AI 驱动的推荐系统等诸多领域具有广泛应用。特别是在大型语言模型(LLMs)近期蓬勃发展的推动下，ANNS 系统已成为现代 AI 基础设施的关键组成部分。

![alt text](./src/x1.png)
检索增强生成(RAG)的典型框架：领域特定知识首先被嵌入为高维向量并存储于向量数据库中。当聊天机器人接收到查询时，会通过 ANNS 引擎从向量数据库中检索最相关的知识，使 LLM 能够将这些知识作为额外上下文进行更精准的推理。


近似最近邻搜索（Approximate Nearest Neighbor Search, ANNS）是处理海量图片、文本特征等数据的核心技术。它的目标并非追求绝对最匹配的结果，**而是通过高效方法获取足够相似的候选集**。在实际应用中，这项技术面临着内存消耗巨大与计算强度极高两大严峻挑战。

为了加速搜索过程，ANNS 系统需要预先构建类似 “目录” 或 “关系网” 的索引结构。常见的索引类型主要有**倒排索引（IVF）和图索引Graph-based**两类。
1. 倒排索引如同图书馆的分类目录，它会将数据预先划分成多个类别，比如 “科技类”“文学类” 等，在执行搜索任务时，只需在相关类别内进行数据比对，从而减少搜索范围。
   
   倒排索引主要由词汇表和倒排记录表（Posting List, PL）组成，词汇表存储着在所有文档集合中出现过的词汇，倒排记录表记录包含对于每一个词汇项对应的所有文档标识符（即文档的ID）以及词频、位置等信息。
   > 假设有以下文档集合：
    文档1: "Hello world"
    文档2: "Hello DataWhale"
    文档3: "Hello easy_vectorDB"
    
    >构建倒排索引后，结果如下：
    Hello: [文档1, 文档2, 文档3]
    world: [文档1]
    DataWhale: [文档2]
    easy_vectorDB: [文档3]
2. 图索引则像是一张关系网，每个数据点都记录着自己的 “最近邻居”，搜索时能够沿着这张关系网快速跳转，实现高效查找。然而，当数据量攀升至十亿甚至千亿级别的规模时，这些索引自身就会占用 TB 级别（相当于数个大型硬盘）的内存空间。如此高昂的内存成本，极大地限制了 ANNS 技术向更大规模数据处理场景的扩展。
ANNS 的核心操作是进行距离计算，即计算数据点之间的相似度，例如比较两张图片特征向量的差异。在处理高维数据（每个数据点包含数百甚至数千个特征值）和超大基数数据时，系统需要执行海量的距离计算，这对算力形成了巨大压力，使得计算强度极高。
在当下热门的检索增强生成（RAG）场景中，ANNS 扮演着至关重要的角色，它是支撑大语言模型（Large Language Model, LLM）实时检索外部知识的核心环节。实际测试数据显示，在整个 LLM 查询流程中，ANNS 阶段所消耗的时间接近 50%，已然成为制约系统响应速度的关键瓶颈。

为降低近似最近邻搜索(ANNS)的内存开销，现有方法主要分为两类：层次化索引(Hierarchical Indexing, HI)与乘积量化(Product Quantization, PQ)。首先，层次化索引通过将索引存储于固态硬盘(SSD)来减少内存占用。以微软商用 ANNS 系统 SPANN为例，该系统将所有基于倒排文件(IVF)的索引（即倒排列表）存放于 SSD，仅通过导航图在内存中维护这些倒排列表的质心。虽然 SPANN 实现了低延迟，但我们发现其并发查询吞吐量存在明显瓶颈，在高端 SSD 上仅能支持最多四个 CPU 线程的峰值性能（第 2.1 节）。这种有限的可扩展性制约了其在需要高吞吐量 AI 应用中的实用性。其次，乘积量化是另一种有效降低内存成本的技术。该向量压缩方法可将高维向量的内存占用量减少高达 95%，同时还能将 ANNS 速度提升数倍。但由于 PQ 属于有损压缩方案，更高的压缩率往往会导致查询精度下降。 对于某些要求高准确率的场景（如召回率@0），这种情况通常是不可接受的。


在大数据与人工智能蓬勃发展的当下，近似最近邻搜索（ANNS）作为数据库和 AI 基础设施的关键部分，面临着数据规模不断扩大带来的性能、成本和精度挑战。FusionANNS,一种高效的CPU/GPU协同处理框架，用于解决海量向量数据的近似最邻近搜索ANNS问题，其核心是通过协同过滤和重排序机制，显著减少CPU、GPU和SSD之间的数据交换，突破I/O性能瓶颈，同时实现高吞吐、低延迟、低成本和高精度。

具体包含三大设计：（1）多层级索引避免 CPU 与 GPU 间数据交换；（2）启发式重排序在保证高精度前提下消除冗余 I/O 与计算；（3）冗余感知的 I/O 去重进一步提升 I/O 效率。

## 一、量化 (PQ) 核心流程详解
1.1 Codebook 构建（离线阶段）
在 FusionANNS 系统中，产品量化的第一步是构建 Codebook，这一过程在离线阶段完成。输入为 10,000 个 512 维原始向量，目标是生成 8 个子空间的 256 个聚类中心。其实现逻辑可通过以下 Python 代码示例呈现：
def build_codebook(vectors):
    codebooks = []
    for i in range(8):  # 8个子空间
        start_dim = i * 64
        end_dim = (i+1) * 64
        subspace = vectors[:, start_dim:end_dim]  # 提取64维子空间
        
        # 执行k-means聚类(k=256)
        centroids = kmeans(subspace, k=256)
        codebooks.append(centroids)  # 256x64矩阵
    return codebooks

从数学角度来看，子空间划分遵循公式\(\text{Group}_i = [64i+1, 64(i+1)] \quad i \in [0,7]\)，而每个子空间生成的聚类中心矩阵表示为\(C_i \in \mathbb{R}^{256 \times 64}\)。通过这样的方式，为后续的向量量化奠定基础。
1.2 向量量化（在线阶段）
在线阶段，系统对输入的单个 512 维向量\(X = (x_1,x_2,...,x_{512})\)进行量化操作，输出 8 字节压缩编码。具体实现如下：
def quantize_vector(vector, codebooks):
    compressed = []
    for i in range(8):
        subvec = vector[i*64 : (i+1)*64]
        distances = [euclidean(subvec, centroid) for centroid in codebooks[i]]
        idx = np.argmin(distances)  # 找到最近聚类中心索引
        compressed.append(idx)      # 0-255整数
    return compressed  # 例：[256,78,3,41,25,97,62,187]

经过这样的量化过程，原始向量的大小从 512×4=2048 字节大幅压缩至 8 字节，实现了256:1的惊人压缩率，有效降低了内存占用，提升了数据处理效率。
1.3 查询距离计算（GPU 加速）
在查询距离计算环节，系统充分利用 GPU 加速能力。首先，对查询向量 Q 进行同样的子空间划分，得到\(Q = (q_1,q_2,...,q_8)\)。接着，计算子空间距离表，其计算公式为：
$
\text{DistanceTable}[i][j] = ||q_i - C_i[j]||^2
\quad \begin{array}{c} i \in [0,7] \\ j \in [0,255] \end{array}
$
然后，根据量化编码快速计算近似距离：
$
\text{Dist}(Q,X) \approx \sum_{k=1}^{8} \text{DistanceTable}[k][\text{code}_k]
$
为进一步提升计算效率，系统采用 2048 线程并行计算（8 子空间 ×256 中心），在 V100 GPU 上，每个查询的计算耗时仅为0.0046ms，极大地加快了查询响应速度。
二、分层索引与边界优化
2.1 多层级聚类结构
FusionANNS 采用独特的多层级聚类结构，如 ![多层聚类](./src/x12.png) 所示。系统将 10 亿向量依次进行 H1、H2、H3、H4 层聚类，最终形成 Posting List。以 H1 层为例，会聚类成 2 个质心，H2 层有 3 个质心，H3 层 5 个质心，H4 层 8 个质心，通过这种分层聚类方式，有效组织数据，缩小搜索空间。
2.2 边界向量分配算法
在处理边界向量时，FusionANNS 运用核心公式\(v \in C_i \iff \text{Dist}(v,C_i) \leq (1+\epsilon) \times \text{Dist}(v,C_1)\)来决定向量的归属，其中\(C_1\)是最近质心。以一个具体示例来说明，假设\(\text{Dist}(v,C_1) = 0.7\)，\(\text{Dist}(v,C_i) = 0.3\)，\(\epsilon = 0.3\)，则\(0.3 \leq (1+0.3)\times0.7 = 0.91\)，满足条件，该向量会被包含在聚类\(C_i\)中。通过这样的策略，单个向量可归属最多 8 个聚类，在实际测试中，相较于 SPANN，其召回率提升了 32%，显著提高了查询准确性。
三、启发式重排序算法
3.1 动态截断流程
由于 PQ 在距离计算中会导致一定的精度损失，FusionANNS 引入启发式重排序算法来优化查询结果。该算法的动态截断流程可通过以下 Python 代码实现：
def heuristic_reranking(candidates, query_vec, k=10, batch_size=1000, ε=0.4, β=3):
    max_heap = MaxHeap(k)  # 维护Top-k最小堆
    stability_count = 0
    
    for i, batch in enumerate(batch_split(candidates, batch_size)):
        prev_topk = set(max_heap.get_ids())  # 保存前一批Top-k
        
        # 处理当前batch
        for vec_id in batch:
            raw_vec = ssd_read(vec_id)
            dist = distance(query_vec, raw_vec)
            max_heap.push(dist, vec_id)
        
        current_topk = set(max_heap.get_ids())
        Δ = len(current_topk - prev_topk) / k  # 计算变化率
        
        if Δ < ε:
            stability_count += 1
            if stability_count >= β:  # 连续β批变化小
                break
        else:
            stability_count = 0  # 重置计数器
    
    return max_heap.get_sorted()

在这个过程中，系统将重排序过程划分为多个小批量（mini-batch）依次处理，通过不断计算变化率\(\Delta\)来判断结果是否趋于稳定，从而决定是否终止重排序，避免不必要的计算和 I/O 操作。
3.2 变化率 Δ 的数学本质
变化率\(\Delta\)的计算公式为\(\Delta = \frac{|S_n \setminus S_{n-1}|}{k} = \frac{\text{新增Top-k向量数}}{k}\)，其反映了每一批次处理后 Top-k 结果中新增向量的比例。当\(\Delta>ε\)时，说明结果仍在剧烈变化，需要继续处理；当\(\Delta<ε\)时，结果趋于稳定，系统开始准备终止；若连续\(\beta\)次\(\Delta<ε\)，则安全终止重排序。在实际应用中，该算法在不同数据集上均取得了显著效果，如在 SIFT1B 数据集上，全量重排序需要处理 40,000 个向量，而启发式重排序仅需处理 28,000 个，I/O 减少了 30%；在 DEEP1B 数据集上，同样实现了 30% 的 I/O 减少，有效提升了系统性能。
四、存储优化与 I/O 去重
4.1 物理存储布局优化
在存储方面，原始向量大小通常在 128 - 384 字节，而现代 NVMe SSD 的页大小为 4KB，这导致了严重的读放大问题，读放大倍数可达 10 - 32 倍。为解决这一问题，FusionANNS 对物理存储布局进行优化，如 ![物理存储布局优化](./src/x13.png) 所示。系统为每个质心创建专属 Bucket，将向量按到质心距离排序填充到 Bucket 中，然后跨 Bucket 合并填充 4KB 页，以最小化碎片，从而提高存储效率和 I/O 性能。
4.2 二级 I/O 去重机制
FusionANNS 还设计了二级 I/O 去重机制，包括批内合并和批间复用。在批内合并方面，以 Mini-batch 请求 V2, V4, V6 为例，系统通过映射表获取每个向量对应的页 ID，发现 V2 和 V6 位于同一页 P0，V4 位于页 P2，最终实际 I/O 操作只需读取 2 次页面（P0 和 P2），替代了原本 3 次的 I/O 请求。在批间复用方面，若 Batch0 已加载 P0（包含 V2、V6）和 P2（包含 V4）到缓存中，当 Batch1 请求 V5（位于 P2）、V8（位于 P1）、V9（位于 P3）时，由于 P2 已在缓存中，Batch1 实际只需读取 P1 和 P3 两次页面即可。通过这样的 I/O 去重机制，在实际测试中，随机存储情况下 I/O 次数为 40,000 次，数据读取量为 160MB，而经过优化后，I/O 次数减少到 30,800 次，数据读取量降低至 123MB，I/O 次数和数据读取量均减少了 23%。
五、端到端查询流程
5.1 系统架构
FusionANNS 的端到端查询流程涉及多个组件协同工作，其流程如![系统架构序列](./src/x11.png) 所示。当 Client 发送查询向量 Q 后，CPU 首先遍历导航图，获取 Top-64 候选列表，然后将向量 ID 列表发送给 GPU。GPU 从 HBM 加载 PQ 向量，进行并行距离计算，并将 Top-N 候选 ID 返回给 CPU。接着，CPU 按照优化后的存储策略从 SSD 读取原始向量，进行动态重排序，最后将最终的 Top-K 结果返回给 Client。整个过程高效有序，充分发挥了各组件的优势。

六、性能实验与工业价值
6.1 性能对比实验
为验证 FusionANNS 的性能优势，我们在特定实验环境下进行测试。实验环境配置为：CPU 采用 2×Xeon 64-core，GPU 为 NVIDIA V100（32GB HBM），SSD 使用 Samsung 990Pro 2TB。在吞吐量对比（QPS）方面，不同数据集下的实验结果如 ![吞吐量对比图](./src/x14.png) 所示，FusionANNS 在 SIFT1B、SPACEV1B、DEEP1B 等数据集上，相较于 SPANN 和 RUMMY，QPS 均有显著提升，展现出强大的处理能力。
6.2 工业应用场景
在工业应用中，FusionANNS 可有效优化 RAG 架构，如 [此处插入 RAG 架构优化示意图] 所示。当用户提问后，Query 经过嵌入处理进入 FusionANNS 引擎，引擎从知识库中快速检索相关向量，获取 Top-K 相关文档，为 LLM 生成回答提供准确信息。在实际应用中，原本占比 50% 的延迟降低至 10%，对于 10 亿级向量的检索，P99 延迟小于 100ms。其适用场景广泛，涵盖法律 AI（如 ChatLaw 千亿级法律条文检索）、家装设计（如 ChatHome 百万级 3D 模型检索）、金融风控（如 Xuanyuan 2.0 实时交易监测）、电商推荐（十亿级商品向量实时匹配）等多个领域，为各行业的智能化发展提供了有力支持。
七、结论与创新价值
7.1 核心突破
FusionANNS 在多个方面实现了核心突破。在存储方面，通过 PQ 压缩率达到 256:1，多层级索引将内存占用降低为 SPANN 的 1/8；计算范式上，采用 CPU-GPU 协同模式，CPU 负责导航，GPU 进行并行计算，使数据传输量减少 99%；在优化策略上，启发式重排序减少了 30% 的 I/O 操作，冗余感知存储降低了 23% 的读放大，全面提升了系统性能。
7.2 行业影响
从行业角度来看，FusionANNS 具有重要影响。在成本方面，实现千亿向量检索的硬件成本低于 $8,000；性能上，QPS 提升 13.1 倍，延迟小于 10ms P99；在生态建设中，有望成为 LLM+RAG 基础设施的标准组件，推动人工智能领域的进一步发展。
最终实现：在十亿级 ANNS 中首次同时满足：高吞吐 (10k+ QPS)｜低延迟 (<10ms)｜高精度 (Recall@10>95%)｜低成本 (<$10k)，为大数据和人工智能领域的向量搜索问题提供了极具价值的解决方案。



### 三大核心技术
1. **多层级索引结构（Multi-tiered Indexing）**  
   - **存储策略**：
     | 设备         | 存储内容                     | 关键优势                          |
     |--------------|------------------------------|-----------------------------------|
     | **SSD**      | 原始向量（Raw Vectors）      | 低成本存储海量数据                |
     | **GPU HBM**  | PQ压缩向量（高压缩比）       | 显存容纳十亿级向量，避免数据交换  |
     | **CPU内存**  | 向量ID列表 + 导航图（无内容）| 传输量减少99%（仅传ID而非向量内容）|
   - **突破**：消除CPU-GPU间冗余数据传输，解决PCIe带宽瓶颈。

2. **启发式重排序（Heuristic Re-ranking）**  
   - **动态截断机制**：
     - 将重排序拆分为**小批次（Mini-batch）** 顺序执行。
     - 每批完成后计算**结果改进率**：
       \[
       \Delta = \frac{|S_n - S_n \cap S_{n-1}|}{k} \quad \text{(当前批与上批结果的差异率)}
       \]
     - 若连续β批的Δ < 阈值ε，则提前终止重排序。
   - **效果**：减少30% I/O和计算，精度损失<1%。

3. **冗余感知I/O去重（Redundancy-aware I/O Deduplication）**  
   - **优化策略**：
     - **存储布局**：相似向量紧凑存储（按聚类中心分桶）。
     - **去重机制**：
       - **批内合并**：同SSD页的I/O请求合并为单次读取。
       - **批间复用**：DRAM缓存复用已加载SSD页。
   - **解决痛点**：原始向量（128-384B）远小于SSD页（4KB），消除读放大。

---

### 性能突破（对比SOTA系统）
| 对比项          | vs. SSD方案 (SPANN)       | vs. GPU内存方案 (RUMMY)   |
|-----------------|---------------------------|---------------------------|
| **吞吐量(QPS)** | ↑ **9.4–13.1倍**          | ↑ **2.4–4.9倍**           |
| **成本效率**    | ↑ **5.7–8.8倍** (QPS/$)   | ↑ **2.3–6.8倍** (QPS/$)   |
| **内存效率**    | ↑ **13.1倍** (QPS/GB)     | ↑ **32.4倍** (QPS/GB)     |
| **硬件需求**    | 单GPU (如V100) + SSD      | 需TB级内存 + 高端GPU       |

---

### 解决的核心挑战
| 挑战                                | 解决方案                          | 关键效果                     |
|-------------------------------------|-----------------------------------|------------------------------|
| GPU显存不足 → 频繁数据交换          | 多层级索引 + 仅传向量ID           | 消除CPU-GPU数据传输瓶颈      |
| PQ压缩导致精度损失 → 需重排序       | 动态启发式重排序                  | 最小化I/O+计算，保精度       |
| SSD小粒度I/O效率低 → 读放大严重     | 存储布局优化 + I/O去重            | 减少23% I/O操作              |

---
























### Reference
[1] [FusionANNS: An Efficient CPU/GPU Cooperative Processing Architecture for Billion-scale Approximate Nearest Neighbor Search](https://arxiv.org/html/2409.16576v1#bib.bib14)