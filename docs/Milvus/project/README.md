# 实践项目
> 部分实践项目来自Milvus和ToWhere官方社区，本教程对其进行了部分修改和完善。
1. 文档的url切割处理：处理包含url的数据示例[url处理实践](./url_process/front.py)
2. 通用向量化处理器：实现一键对pdf、md、txt、pic文件的向量化存储[Cre_milivus](./Cre_milvus/introduction.md)
   * Cre_milvus作为本教程Milvus部分的主项目，
   * 后续的k8s+loki将与之结合，
   * 该项目包含Meta-Chunking中PPL、MSP、动态阈值、元块合并、语义补全
   * PDF、TXT、MD、（结构化、非结构化）数据处理与存储
   * PIC（JPG、PNG）图片的向量化存储
   * Milvus的基本操作
   * locust测试
   * VectorDBench 测试
   * FusionANNS的实践，包含codeBook、DistanceTable的构建、分层PQ、启发式重排序、反馈控制、IO去重
3. 基于 Kubernetes 部署 Grafana + Loki 监控 Milvus 日志[k8s+loki](./k8s+loki/README.md)
4. Meta-chunking论文代码demo[Meta-chunking](./Meta_chunking/README.md)
5. locust测试本地Milvus性能[locust](./locustProj/README.md)

任务流程安排：
1. 关闭PIC
2. 数据的向量化与插入
3. Meta-chunking:PPL
4. Meta-chunking:MSP,动态阈值、元块合并
5. Meta-chunking:语义补全
6. k8s+loki:日志地址
7. 测试：locust
8. 开启PIC，处理逻辑
9. 测试：VectorDBench
10. FusionANNS：启发式重排序和反馈控制模型
11. ...
12. FusionANNS



## Need to know
### 构建数据集要求
**噪声、重复、低质数据会污染知识库，导致检索到无关内容。**
解决方案：
1. 清洗数据：去除HTML标签、特殊符号、乱码等噪声。
2. 去重：合并相似内容，避免冗余数据干扰检索。
3. 标准化：统一文本格式（如日期、单位）、大小写、标点符号。
4. 质量筛选：优先保留权威来源、高可信度的内容。
   
**数据与场景的匹配性问题：知识库与应用场景偏离会导致检索失效。**

解决方案：
1. 场景过滤：仅保留与目标任务相关的数据（例如医疗场景需剔除无关行业内容）。
2. 动态更新：定期增量更新数据，避免时效性内容过期。
3. 冷启动优化：初期可引入人工标注的高质量种子数据。

**安全与合规风险问题：随意导入数据可能泄露敏感信息或引入偏见。**

解决方案：
1. 敏感信息过滤：使用NER识别并脱敏（如身份证号、电话号码）。
2. 偏见检测：通过公平性评估工具（如Fairness Indicators）筛查歧视性内容。
3. 权限控制：对知识库分级访问，限制敏感数据检索权限。

还有以下注意事项：

**文本分块（Chunking）需策略化问题：随意分块可能导致语义不完整，影响向量表示。**

解决方案：
1. 按语义切分：使用句子边界检测、段落分割或基于语义相似度的算法（如BERT句间相似度）。
2. 动态调整块大小：根据数据特性调整（例如技术文档适合较长的块，对话数据适合短块）。
3. 重叠分块：相邻块保留部分重叠文本，避免关键信息被切分到边缘。

**向量化模型的适配性问题：直接使用通用模型可能无法捕捉领域语义。**

解决方案：
1. 领域微调：在领域数据上微调模型（如BERT、RoBERTa）以提升向量表征能力。
2. 多模态支持：若包含图表、代码等，需选择支持多模态的模型（如CLIP、CodeBERT）。
3. 轻量化部署：权衡精度与效率，可选择蒸馏后的模型（如MiniLM）。

**索引结构与检索效率问题：海量数据未经优化会导致检索延迟。**

解决方案：
1. 分层索引：对高频数据使用HNSW，长尾数据用IVF-PQ（Faiss或Milvus）。
2. 元数据过滤：为数据添加标签（如时间、类别），加速粗筛过程。
3. 分布式部署：按数据热度分片，结合缓存机制（如Redis）提升响应速度。

补充说明：**向量知识库数据集也要是问答对？**

将数据整理成问答对（QA Pair）形式是一种优化策略，而非必要步骤。但这种方式在特定场景下能显著提升检索和生成的效果。

以下是其核心原因和适用场景的分析：

1. 为什么问答对形式能优化RAG？
  
   （1）**精准对齐用户查询意图问题**：用户输入通常是自然语言问题（如“如何重置密码？”），而知识库若存储的是纯文本段落（如技术文档），检索时可能因语义差异导致匹配失败。
   问答对的优势：直接以“问题-答案”形式存储知识，检索时相似度计算更聚焦于“问题与问题”的匹配（Question-Question Similarity），而非“问题与段落”的匹配。
   例如，若知识库中存有QA对 Q: 如何重置密码？ → A: 进入设置页面，点击“忘记密码”...，当用户提问“密码忘了怎么办？”时，即使表述不同，向量模型也能捕捉到语义相似性。
   
   （2）**降低生成模型的负担问题**：若检索到的是长文本段落，生成模型（如GPT）需要从段落中提取关键信息并重组答案，可能导致信息冗余或遗漏。
   问答对的优势：答案部分已是对问题的直接回应，生成模型只需“改写”或“补充”答案，而非从头生成，降低幻觉风险。
   例如，QA对中的答案已结构化（如步骤列表），生成结果更规范。
   
   （3）**提升检索效率与召回率问题**：传统分块检索可能因文本块过长或过短导致关键信息丢失（如答案分散在多个段落）。
   问答对的优势：每个QA对是自包含的语义单元，检索时直接返回完整答案，减少上下文碎片化问题。可针对高频问题设计专用QA对，提高热门问题的响应速度和准确性。

2. 哪些场景适合问答对形式？
   
   （1）**任务型对话系统适用场景**：客服机器人、技术支持、医疗咨询等垂直领域。原因：用户需求明确，答案通常简短且结构化（如操作步骤、诊断建议）。案例：用户问：“如何退订会员？” → 直接匹配QA对中的答案：“登录账号→进入订阅管理→点击取消”。
   
   （2）**FAQ（常见问题解答）库适用场景**：产品帮助文档、政策解读等。原因：FAQ天然适合QA形式，直接覆盖高频问题。案例：知识库存储 Q: 保修期多久？ → A: 本产品保修期为2年。
   
   （3）**知识密集型生成任务适用场景**：需要精确引用事实的场景（如法律咨询、学术问答）。原因：QA对中的答案可作为“事实锚点”，减少生成模型的自由发挥。案例：用户问：“《民法典》规定离婚冷静期多久？” → 返回QA对中的法条原文。
   
问答对构建的注意事项并非所有数据都适合QA形式避免强制转换：叙述性文本（如小说、新闻）或开放域知识（如百科条目）更适合以段落或实体为中心存储。强行拆分为QA可能导致信息割裂（例如将“量子力学发展史”拆解为多个不连贯的问答）。
