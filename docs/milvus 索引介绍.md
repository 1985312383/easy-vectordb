### 如何选择合适的索引
**ANNS向量索引**
近邻检索算法，该算法不局限于返回相似度最高的的topk结果，而是只搜索目标的近邻，在可以接受的范围内用精度来换速度。

根据实现方法，ANNS向量索引可以分为四种类型：基于树、基于图、基于哈希和基于量化。

**浮点嵌入的索引**

对于n维浮点嵌入，其占用的存储空间为n*float的大小，而用于浮点嵌入的距离度量是欧氏距离L2和内积IP。

这些类型的索引包括FLAT,IVF_FLAT,IVF_PQ,IVF_SQ8,HNSW,HNSW_SQ,HNSW_PQ,HNSW_PRQ 和SCANN ，用于基于 CPU 的 ANN 搜索。
1. **FLAT**
   对于需要完美的精确度（100%召回率）并且数据集比较小，FLAT不压缩向量，可以将FLAT的结果作为其他索引的比较点。
   
   FLAT采用的是暴力搜索，不适合海量的数据。

   在搜索的时候，可以指定度量metric_type为L2或IP

2. **IVF_FLAT**
   高速查询、尽可能高的召回率

   IVF_FLAT是FLAT的改进版，它将数据集分成多个子集，每个子集称为一个“聚类”，然后对每个聚类进行暴力搜索。

   构建的时候需要指定nlist（聚类数量）默认128

   在搜索的时候，支持普通搜索nprobe(要查询的单位数)和范围搜索max_empty_result_buckets（最大空白桶数，默认为2）

3. **IVF_SQ8**
   极高速的查询，内存资源有限，可以接受召回率稍许下降

   IVF_PQ是IVF_FLAT的改进版，它使用PQ（Product Quantization）对每个聚类进行量化，从而减少存储空间和搜索时间。

   当你的电脑配置比较拉的时候，可以选择IVF_SQ8，它比IVF_PQ更节省内存，但精度会稍微低一些。这种索引可以通过执行标量量化SQ，将每个FLOAT（4字节）转换为UINT8（1字节）。这样可以减少四分之三的磁盘、CPU和GPU内存消耗。

   参数同上一条

4. **IVF_PQ**
   高速查询、内存资源有限，可以接受召回率稍许下降

   PQ（乘积量化），把原始高维的向量分解为低维的笛卡尔乘积，每个低维向量称为一个“子向量”，然后对每个子向量进行量化。乘积量化不需要计算目标向量与所有单元中心的距离，而是能够计算目标向量与每个低维空间聚类中心的距离。

   IVF_PQ先进行IVF索引聚类，然后再对向量的乘积进行量化，时间换内存。

5. **SCANN**
   极高速查询、要求尽可能高的召回率，要求内存资源大

   可扩展近邻，与上面的PQ相似，但是SCANN是专门为GPU优化的，在GPU上运行速度更快。

6. **HNSW**
   极高速查询、要求尽可能高的召回率，要求内存资源大

   分层导航小世界图，是一种基于图的索引算法，根据一定的规则构建多层导航结构，在这种结构中，上层较为稀疏，节点之间的距离较远；下层较为密集，节点的距离相对较近。为了提高性能，HNSW 将图中每层节点的最大度数限制为M 。此外，您还可以使用efConstruction （建立索引时）或ef （搜索目标时）来指定搜索范围。

7. **HNSW_SQ**
   稍慢于HNSW的速度，内存有限，可以接受召回率稍许下降

   SQ是一种根据浮点数据的大小将其离散化为一组有限数值的技术。
   
   例如：

      SQ6 表示量化为2的6次方=64个离散值。

   这种方法减少了内存占用，又保留了数据的基本结构，结合了SQ，HNSW_SQ可以在索引大小和精确度之间进行可控的权衡，同时保持较高的每秒查询次数（QPS）性能。与标准 HNSW 相比，它只会适度增加索引构建时间。
8. **HNSW_PQ**
   比SQ稍慢的速度，内存！非常的！有限，可以接受召回率明显下降

   PQ将向量分解为多个子向量，每个子向量根据kmeans算法找到最近的那个中心点，并以此中心点作为其近似子向量。与 PQ 相结合，HNSW_PQ 可以在索引大小和准确性之间进行可控的权衡，但在相同的压缩率下，它的 QPS 值和召回率都比 HNSW_SQ 低。与 HNSW_SQ 相比，它建立索引的时间更长。
9.  **HNSW_PRQ**
   跟PQ差不多的速度、内存资源非常有限，召回率稍微下降

   与PQ相似，也是将向量分为多个子向量，每个子向量将被编码为nbits 。完成 pq 量化后，它会计算向量与 pq 量化向量之间的残差，并对残差向量应用 pq 量化。总共将进行nrq 次完整的 pq 量化，因此长度为dim 的浮动向量将被编码为m ⋅ nbits ⋅ nrqbits。

   HNSW_PRQ 与乘积残差量化器（PRQ）相结合，在索引大小和精确度之间提供了更高的可控权衡。与 HNSW_PQ 相比，在相同的压缩率下，HNSW_PRQ 的 QPS 值和召回率几乎相当。，建立索引的时间可能会增加数倍。

**二进制嵌入索引**

1. **BIN_FLAT**
   于FLAT完全相同，但只能用于二进制嵌入。
2. **BIN_IVF_FLAT**
   与IVF_FLAT完全相同，但只能用于二进制嵌入。

**稀疏嵌入式索引**
稀疏嵌入式索引仅支持IP 和BM25 （用于全文检索）度量。

**GPU索引**
前提：极高吞吐量的场景，与使用 CPU 索引相比，使用 GPU 索引并不一定能减少延迟。

1. **GPU_CAGRA**
   GPU_CAGRA 是为 GPU 优化的基于图的索引。内存使用量约为原始向量数据的 1.8 倍。
  
   构建时有如下的参数：
   * intermediate_graph_degree 通过在剪枝前确定图的度数来影响召回率和构建时间，推荐32/64
   * graph_degree 通过设置剪枝后图形的度数来影响搜索性能和召回率。这两个度数之间的差值越大，构建时间就越长。其值必须小于intermediate_graph_degree 的值。
   * build_algo 选择剪枝前的图形生成算法。可能的值：IVF_PQ:提供更高的质量，但构建时间较慢。NN_DESCENT提供更快的生成速度，但召回率可能较低。
   * cache_dataset_on_device 决定是否在 GPU 内存中缓存原始数据集。可能的值“true”:缓存原始数据集，通过完善搜索结果提高召回率。“false”不缓存原始数据集，以节省 GPU 内存。
   * adapt_for_cpu 决定是否使用 GPU 建立索引和使用 CPU 进行搜索。将该参数设置为true 时，搜索请求中必须包含ef 参数。
   
   查询时有如下参数：
   * itopk_size	决定搜索过程中保留的中间结果的大小。较大的值可能会提高召回率，但会降低搜索性能。它至少应等于最终的 top-k（极限）值，通常是 2 的幂次（例如 16、32、64、128）。
   * search_width	指定搜索过程中进入 CAGRA 图的入口点数量。增加该值可以提高召回率，但可能会影响搜索性能（如 1、2、4、8、16、32）。
   * min_iterations /max_iterations	控制搜索迭代过程。默认设置为0 ，CAGRA 会根据itopk_size 和search_width 自动确定迭代次数。手动调整这些值有助于平衡性能和准确性。
   * team_size	指定用于在 GPU 上计算度量距离的 CUDA 线程数。常用值是 2 的幂次，最高可达 32（例如 2、4、8、16、32）。它对搜索性能影响不大。默认值为0 ，Milvus 会根据向量维度自动选择team_size 。
   * ef	指定查询时间/准确性的权衡。ef 值越高，搜索越准确，但速度越慢。如果在建立索引时将adapt_for_cpu 设置为true ，则必须使用此参数。范围：[top_k, int_max]

2. **GPU_IVF_FLAT**
   需要与原始数据大小相等的内存。

   和IVF_FLAT类似，也是将数据划分为nlist（群组单位数）聚类单元，然后比较目标输入向量和每个聚类中心的距离。随着目标输入向量数 (nq) 和要搜索的簇数 (nprobe要查询的单位数) 的增加，查询时间也会急剧增加。

3. **GPU_IVF_PQ**
   占用内存较少，具体取决于压缩参数设置。

   PQ时乘积量化，将原始高维的向量空间均匀分解为低维向量空间的笛卡尔乘积，然后对分解后的低维向量进行量化。乘积量化不需要计算目标向量与所有单元中心的距离，而是能够计算目标向量与每个低维空间聚类中心的距离，大大降低了算法的时间复杂度和空间复杂度。

   IVF_PQ先进行IVF聚类，然后再对向量的乘积进行量化。其索引文件比 IVF_SQ8 更小，但在搜索向量时也会造成精度损失。

4. **GPU_BRUTE_FORCE**
   需要与原始数据大小相等的内存。

   专为对召回率要求极高的情况定制，通过暴力搜索，包装召回率为1。它只需要度量类型 (metric_type) 和 top-k (limit) 作为索引构建和搜索参数。

