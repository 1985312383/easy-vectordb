### 关于两种聚类算法
**K-Means**
k-means是一种基于划分的聚类算法，主要思想是把数据划分到k个簇，每个簇都有中心点。
该算法速度快，形成的簇近似于球形，适合于大量的、简单的、规则的数据集。
1. 用户选择簇的数量
2. 随机选择K个点作为中心点
3. 将每个样本分配到距离最近的质心所在的簇
4. 对每个簇重新计算所有成员的平均值作为新的质心
5. 重复步骤3和4，直到质心不在变化或者到达最大的迭代次数
   
**原理：** k-means 的核心思想是，把数据分成 k 个群组（也叫簇），每个群组都有一个“中心点”（也叫质心），目标是让每个点都尽可能靠近自己群组的中心点。简单来说，就是“物以类聚，人以群分”。

**步骤：**

选中心： 先随机选 k 个点，把它们当成初始的中心点。

分堆： 把每个数据点都分到离它最近的中心点所在的群组。

算中心： 重新计算每个群组的中心点（通常是这个群组里所有点的平均值）。

重复： 重复 “分堆” 和 “算中心” 这两步，直到中心点不再怎么变化，或者达到你设定的最大循环次数。

**HDBSCAN**
HDBSCAN聚类是一种基于密度的聚类算法。
该算法速度慢，形成的簇是任意形状的，但适合于复杂的、含噪声的数据集。
1. 通过最小样本数和最小簇大小来估计每个点的密度，也就是看这个点周围有多少邻居
2. 基于点之间的距离和密度关系构建最小生成树，代表两个点的距离
3. 通过不断的切割形成不同密度的簇，也就是说切割哪些距离很长的边（距离很远的点），哪些怎么都连接不上的点就是噪声点
4. HDBSCAN算法可以自动判断分几组，还会自动判断哪些组最稳定

**核心概念：**

核心距离： 对于每个点，找到包含至少 minPts 个点的最小半径，这个半径就是该点的核心距离。

可达距离： 点 A 到点 B 的可达距离是：点 B 的核心距离 和 A 到 B 的实际距离，两者取最大值。

互达性图： 基于可达距离构建的图，距离越小，连接越紧密。

簇的提取： 通过在互达性图上进行聚类，提取簇。

**步骤（简化版）：**

算密度： 评估每个点周围的密度。

建树： 构建一个层次聚类树，把密度相近的点放在一起。

剪枝： 根据密度和连通性，对聚类树进行剪枝，去除噪声和不稳定的簇。

提取簇： 从剪枝后的树中提取最终的簇。

请理解聚类的概念,可以参考哔哩哔哩中zilliz的讲解视频,在二维平面上,运用聚类算法可以更好的将相似的数据聚在一起，从而提高检索性能。

### 关于聚类的时机
下面有三种使用聚类算法的时机：
1. 如果检索性能是首要目标：
   * 在数据存储时进行聚类，并将聚类标签存储到数据库中。
   * 检索时直接利用聚类标签快速定位相关数据
2. 如果数据动态变化比较频繁：
   * 在检索时对召回的数据进行分类，动态分析数据分布
3. 如果需要离线数据分析
   * 定期对数据进行聚类，用于分析或推荐系统
### 关于K-means聚类算法的详解
这一部分将非常多，主要包含论文的解读和分析，如果你对聚类算法感兴趣，可以去看这一部分：[K-means聚类算法详解](../chapter4/K-mean算法详解.md)，他可以为你的项目优化提供一些优化的思路，但如果你只是想了解，那么你看完这个介绍部分就行了。


### Final
感谢读完！🎉
这一部分大部分都是文字，如果你想要看到效果，请前往[Cre_milvus](../project/Cre_milvus/readme.md)实践项目，在这个项目中，将会实际的为您展示聚类的实际效果，同样的如果您觉得刚刚的这个Cre_milvus太慢了（向量化没有调用什么API，将非常消耗CPU和内存，会让你的电脑风扇嗷嗷叫），你可以选择在[HDBSCAN](../project/milvus_hdbscan/hdbscan_clustering_with_milvus.ipynb)这个项目中更快的看到聚类效果！